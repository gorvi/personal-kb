# 参考资料：AI内容生产工作流 - 从话题挖掘到文章生成

## 系统化内容生产：信息聚合 → 话题库 → 内容重构

> 核心方法：热点监控 + 话题库 + AI重构  > 目标：持续产出高质量、有时效性的内容  > 整理时间：2026-02-28

---

## 一、为什么需要这个工作流？

### 传统内容生产的痛点

| 痛点 | 表现 | 后果 |
|------|------|------|
| **不知道写什么** | 每天想选题很痛苦 | 断更、质量不稳定 |
| **追热点太慢** | 看到热点时已经凉了 | 错过流量窗口 |
| **内容同质化** | 别人写过的不想重复写 | 缺乏差异化 |
| **信息过载** | 信息太多，筛选耗时 | 效率低下 |

### AI时代的解决方案

```
信息聚合（自动） → 话题筛选（AI辅助） → 内容重构（AI生成） → 人工审核（可选）
```

---

## 二、工作流架构

### 阶段1：信息聚合（自动采集）

#### 1.1 头部源站点监控

| 类型 | 来源 | 抓取方式 |
|------|------|----------|
| **行业资讯** | 36氪、虎嗅、极客公园 | RSS/API/爬虫 |
| **社交媒体** | 微博热搜、知乎热榜 | API |
| **技术社区** | GitHub Trending、Hacker News | API/RSS |
| **自媒体** | 小红书热门、即刻圈子 | 爬虫/人工精选 |
| **竞品动态** | 竞品公众号最新文章 | RSS/爬虫 |

#### 1.2 自媒体达人监控

**选择标准**：
- 粉丝量：10万+
- 互动率：点赞/阅读 > 5%
- 更新频率：每周2篇+
- 内容质量：原创度高

**监控指标**：
- 近期高赞文章（近7天）
- 话题热度趋势
- 评论区热点问题

---

### 阶段2：话题库存储（结构化）

#### 2.1 话题库结构

```json
{
  "topic_id": "unique_id",
  "title": "原始标题",
  "source": "来源站点",
  "source_url": "原始链接",
  "author": "原作者",
  "publish_time": "2026-02-28T10:00:00Z",
  "category": "AI/商业/技术",
  "keywords": ["AI", "自动化", "效率"],
  "engagement": {
    "views": 10000,
    "likes": 500,
    "comments": 100,
    "shares": 50
  },
  "hot_score": 85,  // 热度评分 0-100
  "status": "pending",  // pending/processing/published/rejected
  "extracted_angles": ["角度1", "角度2", "角度3"],
  "ai_analysis": {
    "main_point": "核心观点",
    "controversy": "争议点",
    "audience_interest": "受众兴趣度"
  },
  "created_at": "2026-02-28T12:00:00Z"
}
```

#### 2.2 存储方案

| 方案 | 适用场景 | 优缺点 |
|------|----------|--------|
| **Notion Database** | 个人/小团队 | 可视化好，但自动化弱 |
| **Airtable** | 小团队 | API友好，免费版有限 |
| **飞书多维表格** | 国内团队 | API好，国内快 |
| **本地SQLite** | 技术用户 | 完全自主，需维护 |
| **云数据库** | 大规模 | 专业，有成本 |

**推荐**：飞书多维表格（API好 + 国内访问快）

---

### 阶段3：话题筛选（AI辅助决策）

#### 3.1 筛选维度

| 维度 | 权重 | 说明 |
|------|------|------|
| **热度** | 30% | 阅读量、点赞、互动 |
| **时效性** | 25% | 发布时间（24h/7d/30d） |
| **相关度** | 20% | 与公众号定位的匹配度 |
| **独特性** | 15% | 是否已被大量报道 |
| **可操作性** | 10% | 能否产出差异化内容 |

#### 3.2 AI筛选Prompt

```markdown
# 话题筛选分析

请分析以下话题，给出评分和建议：

## 话题信息
标题：{title}
来源：{source}
热度：{hot_score}/100
发布时间：{publish_time}
关键词：{keywords}

## 分析维度

1. **热度评分** (0-100)
   - 基于阅读量、点赞、互动数据
   - >80分：非常热，立即跟进
   - 60-80分：较热，可以写
   - <60分：一般，除非独特角度

2. **时效性评分** (0-100)
   - 24小时内：100分
   - 7天内：80分
   - 30天内：60分
   - >30天：40分

3. **相关度评分** (0-100)
   - 与"AI+效率工具"定位的匹配度

4. **独特性评分** (0-100)
   - 是否已有大量同质化内容
   - 能否找到差异化角度

5. **可操作性评分** (0-100)
   - 能否产出有实用价值的内容
   - 是否有案例/数据支撑

## 输出格式

综合评分：xx/100
建议：✅强烈推荐 / ⚠️可以考虑 / ❌不建议

推荐理由：
1. xxx
2. xxx

建议角度：
1. 角度1：xxx（预计阅读量xxx）
2. 角度2：xxx（预计阅读量xxx）
3. 角度3：xxx（预计阅读量xxx）

风险提示：
- xxx
```

---

### 阶段4：内容重构（AI生成）

#### 4.1 重构策略

**策略1：角度重构**
```
原文：AI编程工具盘点
新文：小白用AI编程月入过万实战
差异：从盘点→实战案例
```

**策略2：深度重构**
```
原文：OpenClaw发布新功能
新文：我用OpenClaw自动化工作流半个月的心得
差异：从新闻→个人体验
```

**策略3：组合重构**
```
素材1：AI早报（行业趋势）
素材2：个人实战（案例分析）
素材3：数据报告（行业数据）
新文：2026年AI工作流趋势+我的实践经验
差异：多源整合+个人洞察
```

**策略4：反向重构**
```
原文：AI会取代程序员吗？
新文：为什么AI不会取代程序员，但会改变程序员
差异：从焦虑→建设性观点
```

#### 4.2 内容生成Prompt

```markdown
# 内容重构生成

基于以下话题和素材，生成一篇新的公众号文章。

## 原始话题
标题：{original_title}
核心内容：{summary}
关键数据：{key_data}

## 写作要求

1. **新角度**：从"{new_angle}"角度切入
2. **目标受众**：对AI工具感兴趣的职场人
3. **文章结构**：
   - 吸引眼球的标题
   - 痛点引入（共鸣）
   - 3-5个核心观点
   - 每个观点有案例/数据支撑
   - 实用建议（ actionable）
   - 总结+互动引导

4. **语言风格**：
   - 专业但不晦涩
   - 有个人观点和态度
   - 适当使用 emoji
   - 段落短小，适合手机阅读

5. **原创性要求**：
   - 不要直接复制原文
   - 加入自己的理解和洞察
   - 补充新的案例或数据
   - 提出新的观点

## 输出格式

直接输出完整的Markdown格式文章，包含：
- 标题
- 正文（分章节）
- 文末互动问题
```

---

## 三、OpenClaw自动化实现

### 工作流设计

```python
# OpenClaw Skill: ContentPipeline

class ContentPipeline:
    """内容生产流水线"""
    
    def __init__(self):
        self.collectors = [
            RSSCollector(),      # RSS订阅
            WeiboCollector(),    # 微博热搜
            ZhihuCollector(),    # 知乎热榜
            GitHubCollector(),   # GitHub Trending
            CompetitorCollector() # 竞品监控
        ]
        self.topic_db = FeishuDB()  # 飞书多维表格
        self.ai_analyzer = AIAnalyzer()
        self.content_generator = ContentGenerator()
    
    def daily_pipeline(self):
        """每日自动执行"""
        
        # 1. 采集（早上7:00）
        print("📥 开始采集...")
        raw_topics = []
        for collector in self.collectors:
            topics = collector.collect()
            raw_topics.extend(topics)
        print(f"✅ 采集到 {len(raw_topics)} 条原始话题")
        
        # 2. 去重 & 存储
        print("🗄️  存储到话题库...")
        new_topics = self.topic_db.add_topics(raw_topics)
        print(f"✅ 新增 {len(new_topics)} 条话题")
        
        # 3. AI分析评分
        print("🤖 AI分析话题...")
        for topic in new_topics:
            analysis = self.ai_analyzer.analyze(topic)
            topic['hot_score'] = analysis['score']
            topic['ai_analysis'] = analysis
            self.topic_db.update(topic)
        
        # 4. 筛选高潜力话题
        print("🔍 筛选话题...")
        candidates = self.topic_db.query(
            hot_score__gte=70,
            status='pending'
        )
        
        # 5. 推送到审核队列
        print(f"📋 推送 {len(candidates)} 个话题到审核")
        self.push_to_review(candidates)
    
    def generate_content(self, topic_id):
        """生成内容（人工触发或定时）"""
        
        # 获取话题
        topic = self.topic_db.get(topic_id)
        
        # 收集相关素材
        materials = self.collect_materials(topic['keywords'])
        
        # AI生成文章
        article = self.content_generator.generate(
            topic=topic,
            materials=materials,
            style='professional'
        )
        
        # 保存到草稿
        self.save_draft(article)
        
        return article
```

---

## 四、实战：本周即可运行的MVP

### 阶段1：手工版（本周）

**工具组合**：
- 信息源：RSS阅读器（Feedly/Inoreader）
- 话题库：飞书多维表格
- AI分析：OpenClaw手动分析
- 内容生成：OpenClaw生成文章

**每日流程**：
```
7:00  手动浏览RSS，复制3-5个热门话题到飞书
9:00  用AI分析话题，选1-2个高潜力
10:00 AI生成文章初稿
11:00 人工审核修改
12:00 发布
```

### 阶段2：半自动版（下周）

**工具组合**：
- 爬虫：Python + requests
- 话题库：飞书多维表格API
- AI分析：OpenClaw自动分析
- 定时：GitHub Actions / 服务器定时任务

### 阶段3：全自动版（1个月后）

- 全自动化采集
- AI自动筛选
- AI自动生成
- 人工只需审核

---

## 五、内容质量评估

### 发布前检查清单

| 检查项 | 标准 | 工具 |
|--------|------|------|
| **原创度** | >70% | 查重工具 |
| **可读性** | 适合手机阅读 | 人工检查 |
| **信息准确性** | 数据/案例可验证 | 交叉验证 |
| **时效性** | 7天内热点 | 时间戳 |
| **实用性** | 有可操作建议 | 人工判断 |

### 发布后数据追踪

| 指标 | 目标 | 追踪方式 |
|------|------|----------|
| 阅读量 | >1000 | 微信后台 |
| 点赞率 | >3% | 微信后台 |
| 分享率 | >1% | 微信后台 |
| 完读率 | >30% | 微信后台 |
| 涨粉数 | 每篇+10 | 微信后台 |

---

## 六、避坑指南

### ❌ 不要这样做

1. **直接搬运** → 侵权风险，被封号
2. **洗稿重写** → 质量低，用户反感
3. **追过时热点** → 没人看
4. **同质化内容** → 缺乏差异化

### ✅ 应该这样做

1. **信息整合+个人观点** → 增加价值
2. **本地化/垂直化** → 差异化
3. **加入实操案例** → 提高实用性
4. **提前预判热点** → 抢占先机

---

## 七、工具推荐

| 用途 | 工具 | 价格 |
|------|------|------|
| **RSS聚合** | Feedly / Inoreader | 免费/付费 |
| **爬虫** | Python + Scrapy | 免费 |
| **话题库** | 飞书多维表格 | 免费 |
| **AI分析** | OpenClaw / GPT-4 | 按量付费 |
| **查重** | 易撰 / 维权骑士 | 免费/付费 |
| **排版** | 秀米 / 135编辑器 | 免费/付费 |

---

## 相关资源

- 方法论：信息聚合、内容重构、热点追踪
- 工具：RSS、爬虫、飞书多维表格、OpenAI
- 核心概念：内容生产流水线、话题库、AI辅助创作

---

## 关联阅读

- [OpenClaw三个高频使用场景实战](./OpenClaw三个高频使用场景实战.md) - 自动化早报
- [靠靠bot产品助手工作流](./AI产品助手工作流设计案例-靠靠bot.md) - 数据驱动决策
- [如何借助AI比任何人学得快10倍](./如何借助AI比任何人学得快10倍.md) - AI学习方法

---

*整理时间：2026-02-28*  
*标签：#内容生产 #热点追踪 #AI写作 #话题库 #信息聚合*
